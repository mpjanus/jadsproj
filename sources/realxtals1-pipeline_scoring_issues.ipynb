{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pipeline Scoring Issues (on Tileset7) - Aug 2017\n",
    "Created:  24 Aug 2018 <br>\n",
    "Last update: 24 Aug 2018\n",
    "\n",
    "\n",
    "### This is mostly a copy of realxtals1-fullpipeline1, but with a 'break out' to figure out why scores deviate from prior work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will remove warnings messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import imgutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run this cell if you altered imgutils\n",
    "import importlib\n",
    "importlib.reload(imgutils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 2. Data Definitions & Feature Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data:\n",
    "datafolder = '../data/Crystals_Apr_12/Tileset7'\n",
    "n_tiles_x = 3  # mostly for visualization\n",
    "n_tiles_y = 2\n",
    "\n",
    "\n",
    "# Features to use:\n",
    "#feature_funcs = [imgutils.img_mean, imgutils.img_std, imgutils.img_median, \n",
    "#                 imgutils.img_mode,\n",
    "#                 imgutils.img_kurtosis, imgutils.img_skewness]\n",
    "feature_funcs = [imgutils.img_std, imgutils.img_relstd, imgutils.img_mean, \n",
    "                 imgutils.img_skewness,  imgutils.img_kurtosis, imgutils.img_mode]\n",
    "feature_names = imgutils.stat_names(feature_funcs)\n",
    "\n",
    "# Size of the grid, specified as number of slices per image in x and y direction:\n",
    "n_rows = 4\n",
    "n_cols = n_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 3. Import Data & Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image import:\n",
    "print(\"Scanning for images in '{}'...\".format(datafolder))\n",
    "df_imgfiles = imgutils.scanimgdir(datafolder, '.tif')\n",
    "imgfiles = list(df_imgfiles['filename'])\n",
    "print(\"# of images: {} \\n\".format(len(imgfiles)))\n",
    "\n",
    "# feature extraction:\n",
    "print(\"Feature extraction...\")\n",
    "print(\"- Slicing up images in {} x {} patches. \".format(n_rows, n_cols))\n",
    "print(\"- Extract statistics from each slice: {} \".format(', '.join(feature_names)))\n",
    "print(\"...working...\", end='\\r')\n",
    "df = imgutils.slicestats(imgfiles, n_rows, n_cols, feature_funcs)\n",
    "print(\"# slices extracted: \", len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 4. Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data hyper-parameters\n",
    "n_clusters = 3\n",
    "n_important_features = len(feature_names)\n",
    "\n",
    "# algorithm hyper-parameters:\n",
    "kmeans_n_init = 10\n",
    "pca_n_components = None   # i.e. all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ml_pipeline(X, ml_name, ml_algorithm, standardize=True, use_pca=True):\n",
    "    global pca_n_components\n",
    "  \n",
    "    # Setup algorithmic pipeline, including standardization\n",
    "    pipeline = Pipeline([(ml_name, ml_algorithm)])\n",
    "    \n",
    "    # watch the order, pca should happen after scaling, but we insert at 0\n",
    "    if (use_pca): \n",
    "        pipeline.steps.insert(0,('pca', PCA(n_components=pca_n_components)))\n",
    "    if (standardize): \n",
    "        pipeline.steps.insert(0, ('scaling_{0}'.format(ml_name), StandardScaler()))\n",
    "    \n",
    "    # run the pipelines\n",
    "    y = pipeline.fit_predict(X) # calls predict on last step to get the labels\n",
    "\n",
    "    # report score:\n",
    "    score = silhouette_score(X, y)\n",
    "    \n",
    "    return score, y\n",
    "\n",
    "def run_ml_pipelines(df_data, feature_cols, n_clust = n_clusters, standardize=True, use_pca=True):\n",
    "    global pca_n_components, kmeans_n_init\n",
    "    \n",
    "    X = df_data.loc[:,feature_cols]\n",
    "    \n",
    "    # Setup ML clustering algorithms:    \n",
    "    kmeans = KMeans(algorithm='auto', n_clusters=n_clust, n_init=kmeans_n_init, init='k-means++')\n",
    "    agglomerative =  AgglomerativeClustering(n_clusters=n_clust, affinity='euclidean', linkage='complete')  \n",
    "\n",
    "    # run the pipelines\n",
    "    print(\"Executing clustering pipelines...\")\n",
    "    score_kmeans, y_kmeans = run_ml_pipeline(X, 'kmeans', kmeans, standardize = standardize, use_pca = use_pca)\n",
    "    score_hier, y_hier = run_ml_pipeline(X, 'hierarchical', agglomerative, standardize = standardize, use_pca = use_pca)\n",
    "    print(\"Done\\n\")\n",
    "    \n",
    "    # collect data\n",
    "    df_data['kmeans']=y_kmeans\n",
    "    df_data['hierarchical']=y_hier\n",
    "\n",
    "    # report results:\n",
    "    print(\"\\nClustering Scores:\")\n",
    "    print(\"K-means: \", score_kmeans)\n",
    "    print(\"Hierarchical: \", score_hier)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGULAR PIPELINE  \n",
    "def run_kmeans_pipeline1(df_data, feature_cols, n_clust=n_clusters,standardize=True, use_pca=True):\n",
    "    global pca_n_components\n",
    "  \n",
    "    X = df_data.loc[:,feature_cols]\n",
    "    \n",
    "    # Setup algorithmic pipeline, including standardization if enabled\n",
    "    ml_algorithm = KMeans(algorithm='auto', n_clusters=n_clust, n_init=kmeans_n_init, init='k-means++')\n",
    "    ml_name = 'kmeans1'\n",
    "    pipeline = Pipeline([(ml_name, ml_algorithm)])\n",
    "    \n",
    "    # watch the order, pca should happen after scaling, but we insert at 0\n",
    "    if (use_pca): \n",
    "        pipeline.steps.insert(0,('pca', PCA(n_components=pca_n_components)))\n",
    "    if (standardize): \n",
    "        pipeline.steps.insert(0, ('scaling_{0}'.format(ml_name), StandardScaler()))\n",
    "    \n",
    "    #print(pipeline.steps)\n",
    "    \n",
    "    # run the pipelines\n",
    "    y = pipeline.fit_predict(X) # calls predict on last step to get the labels\n",
    "\n",
    "    # report score:\n",
    "    score = silhouette_score(X, y)\n",
    "    \n",
    "    return score, y\n",
    "\n",
    "def run_hierarchical_pipeline1(df_data, feature_cols, n_clust=n_clusters, standardize=True, use_pca=True):\n",
    "    global pca_n_components\n",
    "    \n",
    "\n",
    "    X = df_data.loc[:,feature_cols]\n",
    "    \n",
    "    # Setup algorithmic pipeline, including standardization if enabled\n",
    "    ml_algorithm = AgglomerativeClustering(n_clusters=n_clust, affinity='euclidean', linkage='complete')  \n",
    "    ml_name = 'hier1'\n",
    "    pipeline = Pipeline([(ml_name, ml_algorithm)])\n",
    "    \n",
    "    # watch the order, pca should happen after scaling, but we insert at 0\n",
    "    if (use_pca): \n",
    "        pipeline.steps.insert(0,('pca', PCA(n_components=pca_n_components)))\n",
    "    if (standardize): \n",
    "        pipeline.steps.insert(0, ('scaling_{0}'.format(ml_name), StandardScaler()))\n",
    "    \n",
    "    #print(pipeline.steps)\n",
    "    \n",
    "    # run the pipelines\n",
    "    y = pipeline.fit_predict(X) # calls predict on last step to get the labels\n",
    "\n",
    "    # report score:\n",
    "    score = silhouette_score(X, y)\n",
    "    \n",
    "    return score, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL step-by-step\n",
    "def run_kmeans_pipeline2(df_data, feature_cols, n_clust=n_clusters,standardize=True, use_pca=True):\n",
    "    global pca_n_components\n",
    "  \n",
    "    #print(\"Settings: \", standardize, use_pca)\n",
    "    \n",
    "    X = []\n",
    "    if (standardize):\n",
    "        imgutils.normalize(df_data, feature_cols)\n",
    "        norm_feature_cols = imgutils.normalized_names(feature_cols)\n",
    "        X = df_data.loc[:,norm_feature_cols]\n",
    "    else:\n",
    "        X = df_data.loc[:,feature_cols]\n",
    "    \n",
    "    # Setup algorithmic pipeline, including standardization if enabled\n",
    "    ml_algorithm = KMeans(algorithm='auto', n_clusters=n_clust, n_init=kmeans_n_init, init='k-means++')\n",
    "    ml_name = 'kmeans2'\n",
    "\n",
    "    X_use = X\n",
    "    # watch the order, pca should happen after scaling, but we insert at 0\n",
    "    if (use_pca): \n",
    "        pca = PCA(n_components=pca_n_components)\n",
    "        X_use = pca.fit_transform(X)\n",
    "    \n",
    "    # run the pipelines\n",
    "    y = ml_algorithm.fit_predict(X_use) # calls predict on last step to get the labels\n",
    "\n",
    "    # report score:\n",
    "    score = silhouette_score(X, y)\n",
    "    \n",
    "    return score, y\n",
    "\n",
    "def run_hierarchical_pipeline2(df_data, feature_cols, n_clust=n_clusters, standardize=True, use_pca=True):\n",
    "    global pca_n_components\n",
    "\n",
    "    #print(\"Settings: \", standardize, use_pca)\n",
    "\n",
    "    X = []\n",
    "    if (standardize):\n",
    "        imgutils.normalize(df_data, feature_cols)\n",
    "        norm_feature_cols = imgutils.normalized_names(feature_cols)\n",
    "        X = df_data.loc[:,norm_feature_cols]\n",
    "    else:\n",
    "        X = df_data.loc[:,feature_cols]\n",
    "    \n",
    "    # Setup algorithmic pipeline, including standardization if enabled\n",
    "    ml_algorithm = AgglomerativeClustering(n_clusters=n_clust, affinity='euclidean', linkage='complete')  \n",
    "    ml_name = 'hier2'\n",
    "    \n",
    "    X_use = X\n",
    "    # watch the order, pca should happen after scaling, but we insert at 0\n",
    "    if (use_pca): \n",
    "        pca = PCA(n_components=pca_n_components)\n",
    "        X_use = pca.fit_transform(X)\n",
    "    \n",
    "    # run the pipelines\n",
    "    y = ml_algorithm.fit_predict(X_use) # calls predict on last step to get the labels\n",
    "\n",
    "    # report score:\n",
    "    score = silhouette_score(X, y)\n",
    "    \n",
    "    return score, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline differently composed\n",
    "def run_kmeans_pipeline3(df_data, feature_cols, n_clust=n_clusters,standardize=True, use_pca=True):\n",
    "    global pca_n_components\n",
    "  \n",
    "    X = df_data.loc[:,feature_cols]\n",
    "    \n",
    "    # Setup algorithmic pipeline, including standardization if enabled\n",
    "    ml_algorithm = KMeans(algorithm='auto', n_clusters=n_clust, n_init=kmeans_n_init, init='k-means++')\n",
    "    ml_name = 'kmeans3'\n",
    "    pl_contents = []\n",
    "    \n",
    "    if (standardize): \n",
    "        pl_contents.append(('scaling_{0}'.format(ml_name), StandardScaler()))\n",
    "    if (use_pca):\n",
    "        pl_contents.append(('pca_{0}'.format(ml_name), PCA(n_components=pca_n_components)))\n",
    "    pl_contents.append((ml_name, ml_algorithm))    \n",
    "        \n",
    "    pipeline = Pipeline(pl_contents)\n",
    "    #print(pipeline.steps)\n",
    "\n",
    "    # run the pipelines\n",
    "    y = pipeline.fit_predict(X) # calls predict on last step to get the labels\n",
    "\n",
    "    # report score:\n",
    "    score = silhouette_score(X, y)\n",
    "    \n",
    "    return score, y\n",
    "\n",
    "def run_hierarchical_pipeline3(df_data, feature_cols, n_clust=n_clusters,standardize=True, use_pca=True):\n",
    "    global pca_n_components\n",
    "  \n",
    "    X = df_data.loc[:,feature_cols]\n",
    "    \n",
    "    # Setup algorithmic pipeline, including standardization if enabled\n",
    "    ml_algorithm = AgglomerativeClustering(n_clusters=n_clust, affinity='euclidean', linkage='complete')  \n",
    "    ml_name = 'hier3'\n",
    "    pl_contents = []\n",
    "    \n",
    "    if (standardize): \n",
    "        pl_contents.append(('scaling_{0}'.format(ml_name), StandardScaler()))\n",
    "    if (use_pca):\n",
    "        pl_contents.append(('pca_{0}'.format(ml_name), PCA(n_components=pca_n_components)))\n",
    "    pl_contents.append((ml_name, ml_algorithm))    \n",
    "        \n",
    "    pipeline = Pipeline(pl_contents)\n",
    "    #print(pipeline.steps)\n",
    "\n",
    "    # run the pipelines\n",
    "    y = pipeline.fit_predict(X) # calls predict on last step to get the labels\n",
    "\n",
    "    # report score:\n",
    "    score = silhouette_score(X, y)\n",
    "    \n",
    "    return score, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-by-step but with StandardScaler\n",
    "def run_kmeans_pipeline4(df_data, feature_cols, n_clust=n_clusters,standardize=True, use_pca=True):\n",
    "    global pca_n_components\n",
    "  \n",
    "    X = df_data.loc[:,feature_cols]\n",
    "    X_use = X\n",
    "    \n",
    "    if (standardize):\n",
    "        scaler = StandardScaler()\n",
    "        X_use = scaler.fit_transform(X)\n",
    "\n",
    "    if (use_pca): \n",
    "        pca = PCA(n_components=pca_n_components)\n",
    "        X_use = pca.fit_transform(X_use)        \n",
    "                   \n",
    "    ml_algorithm = KMeans(algorithm='auto', n_clusters=n_clust, n_init=kmeans_n_init, init='k-means++')\n",
    "    ml_name = 'kmeans4'\n",
    "    y = ml_algorithm.fit_predict(X_use) \n",
    "    \n",
    "    # report score:\n",
    "    score = silhouette_score(X, y)\n",
    "    \n",
    "    return score, y\n",
    "\n",
    "def run_hierarchical_pipeline4(df_data, feature_cols, n_clust=n_clusters,standardize=True, use_pca=True):\n",
    "    global pca_n_components\n",
    "  \n",
    "    X = df_data.loc[:,feature_cols]\n",
    "    X_use = X\n",
    "    \n",
    "    if (standardize):\n",
    "        scaler = StandardScaler()\n",
    "        X_use = scaler.fit_transform(X)\n",
    "\n",
    "    if (use_pca): \n",
    "        pca = PCA(n_components=pca_n_components)\n",
    "        X_use = pca.fit_transform(X_use)        \n",
    "                   \n",
    "    ml_algorithm = AgglomerativeClustering(n_clusters=n_clust, affinity='euclidean', linkage='complete')  \n",
    "    ml_name = 'hier4'\n",
    "\n",
    "    y = ml_algorithm.fit_predict(X_use) \n",
    "    \n",
    "    # report score:\n",
    "    score = silhouette_score(X, y)\n",
    "    \n",
    "    return score, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline custom scaler\n",
    "def run_kmeans_pipeline5(df_data, feature_cols, n_clust=n_clusters,standardize=True, use_pca=True):\n",
    "    global pca_n_components\n",
    "  \n",
    "    #print(\"Settings: \", standardize, use_pca)\n",
    "    \n",
    "    X = df_data.loc[:,feature_cols]\n",
    "    \n",
    "    X_use = X\n",
    "    if (standardize):\n",
    "        imgutils.normalize(df_data, feature_cols)\n",
    "        norm_feature_cols = imgutils.normalized_names(feature_cols)\n",
    "        X_use = df_data.loc[:,norm_feature_cols]\n",
    "    \n",
    "    # Setup algorithmic pipeline, including standardization if enabled\n",
    "    ml_algorithm = KMeans(algorithm='auto', n_clusters=n_clust, n_init=kmeans_n_init, init='k-means++')\n",
    "    ml_name = 'kmeans5'\n",
    "    pipeline = Pipeline([(ml_name, ml_algorithm)])\n",
    "    \n",
    "    if (use_pca): \n",
    "        pipeline.steps.insert(0,('pca', PCA(n_components=pca_n_components)))\n",
    "    \n",
    "    #print(pipeline.steps)\n",
    "    \n",
    "    # run the pipelines\n",
    "    y = pipeline.fit_predict(X_use) # calls predict on last step to get the labels\n",
    "\n",
    "    # report score:\n",
    "    score = silhouette_score(X, y)\n",
    "    \n",
    "    return score, y\n",
    "\n",
    "def run_hierarchical_pipeline5(df_data, feature_cols, n_clust=n_clusters, standardize=True, use_pca=True):\n",
    "    global pca_n_components\n",
    "  \n",
    "    #print(\"Settings: \", standardize, use_pca)\n",
    "    \n",
    "    X = df_data.loc[:,feature_cols]\n",
    "    \n",
    "    X_use = X\n",
    "    if (standardize):\n",
    "        imgutils.normalize(df_data, feature_cols)\n",
    "        norm_feature_cols = imgutils.normalized_names(feature_cols)\n",
    "        X_use = df_data.loc[:,norm_feature_cols]\n",
    "    \n",
    "    # Setup algorithmic pipeline, including standardization if enabled\n",
    "    ml_algorithm = AgglomerativeClustering(n_clusters=n_clust, affinity='euclidean', linkage='complete')  \n",
    "    ml_name = 'hier5'\n",
    "\n",
    "    pipeline = Pipeline([(ml_name, ml_algorithm)])\n",
    "    \n",
    "    if (use_pca): \n",
    "        pipeline.steps.insert(0,('pca', PCA(n_components=pca_n_components)))\n",
    "    \n",
    "    #print(pipeline.steps)\n",
    "    \n",
    "    # run the pipelines\n",
    "    y = pipeline.fit_predict(X_use) # calls predict on last step to get the labels\n",
    "\n",
    "    # report score:\n",
    "    score = silhouette_score(X, y)\n",
    "    \n",
    "    return score, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL ALT SCORE (step-by-step) \n",
    "def run_kmeans_pipeline6(df_data, feature_cols, n_clust=n_clusters,standardize=True, use_pca=True):\n",
    "    global pca_n_components\n",
    "  \n",
    "    #print(\"Settings: \", standardize, use_pca)\n",
    "    \n",
    "    X = df_data.loc[:,feature_cols]\n",
    "    \n",
    "    X_use = X\n",
    "    if (standardize):\n",
    "        imgutils.normalize(df_data, feature_cols)\n",
    "        norm_feature_cols = imgutils.normalized_names(feature_cols)\n",
    "        X_use = df_data.loc[:,norm_feature_cols]\n",
    "           \n",
    "    # Setup algorithmic pipeline, including standardization if enabled\n",
    "    ml_algorithm = KMeans(algorithm='auto', n_clusters=n_clust, n_init=kmeans_n_init, init='k-means++')\n",
    "    ml_name = 'kmeans6'\n",
    "\n",
    "    if (use_pca): \n",
    "        pca = PCA(n_components=pca_n_components)\n",
    "        X_use = pca.fit_transform(X_use)\n",
    "    \n",
    "    # run the pipelines\n",
    "    y = ml_algorithm.fit_predict(X_use) # calls predict on last step to get the labels\n",
    "\n",
    "    # report score:\n",
    "    score = silhouette_score(X, y)\n",
    "    \n",
    "    return score, y\n",
    "\n",
    "def run_hierarchical_pipeline6(df_data, feature_cols, n_clust=n_clusters, standardize=True, use_pca=True):\n",
    "    global pca_n_components\n",
    "\n",
    "    #print(\"Settings: \", standardize, use_pca)\n",
    "\n",
    "    X = df_data.loc[:,feature_cols]\n",
    "    \n",
    "    X_use = X\n",
    "    if (standardize):\n",
    "        imgutils.normalize(df_data, feature_cols)\n",
    "        norm_feature_cols = imgutils.normalized_names(feature_cols)\n",
    "        X_use = df_data.loc[:,norm_feature_cols]\n",
    "\n",
    "    \n",
    "    # Setup algorithmic pipeline, including standardization if enabled\n",
    "    ml_algorithm = AgglomerativeClustering(n_clusters=n_clust, affinity='euclidean', linkage='complete')  \n",
    "    ml_name = 'hier6'\n",
    "\n",
    "    # watch the order, pca should happen after scaling, but we insert at 0\n",
    "    if (use_pca): \n",
    "        pca = PCA(n_components=pca_n_components)\n",
    "        X_use = pca.fit_transform(X_use)\n",
    "    \n",
    "    # run the pipelines\n",
    "    y = ml_algorithm.fit_predict(X_use) # calls predict on last step to get the labels\n",
    "\n",
    "    # report score:\n",
    "    score = silhouette_score(X, y)\n",
    "    \n",
    "    return score, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_ml_pipelines(df, feature_names, standardize=True, use_pca=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pipeline-inserts:\")\n",
    "score_k_1, y_k_1 = run_kmeans_pipeline1(df, feature_names, standardize=True, use_pca=False)\n",
    "score_h_1, y_h_1 = run_hierarchical_pipeline1(df, feature_names, standardize=True, use_pca=False)\n",
    "print('K-means 1:', score_k_1)\n",
    "print('Hier. 1:', score_h_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pipeline-inserts PCA:\")\n",
    "score_k_1p, y_k_1p = run_kmeans_pipeline1(df, feature_names, standardize=True, use_pca=True)\n",
    "score_h_1p, y_h_1p = run_hierarchical_pipeline1(df, feature_names, standardize=True, use_pca=True)\n",
    "print('K-means PCA 1:', score_k_1p)\n",
    "print('Hier. PCA 1:', score_h_1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ORIGINAL (step-by-step):\")\n",
    "score_k_2, y_k_2 = run_kmeans_pipeline2(df, feature_names, standardize=True, use_pca=False)\n",
    "score_h_2, y_h_2 = run_hierarchical_pipeline2(df, feature_names, standardize=True, use_pca=False)\n",
    "print('K-means 2:', score_k_2)\n",
    "print('Hier. 2:', score_h_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ORIGINAL PCA (step-by-step):\")\n",
    "score_k_2p, y_k_2p = run_kmeans_pipeline2(df, feature_names, standardize=True, use_pca=True)\n",
    "score_h_2p, y_h_2p = run_hierarchical_pipeline2(df, feature_names, standardize=True, use_pca=True)\n",
    "print('K-means PCA 2:', score_k_2p)\n",
    "print('Hier. PCA 2:', score_h_2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Alt. Pipeline:\")\n",
    "score_k_3, y_k_3 = run_kmeans_pipeline3(df, feature_names, standardize=True, use_pca=False)\n",
    "score_h_3, y_h_3 = run_hierarchical_pipeline3(df, feature_names, standardize=True, use_pca=False)\n",
    "print('K-means 3:', score_k_3)\n",
    "print('Hier. 3:', score_h_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Alt. Pipeline PCA:\")\n",
    "score_k_3p, y_k_3p = run_kmeans_pipeline3(df, feature_names, standardize=True, use_pca=True)\n",
    "score_h_3p, y_h_3p = run_hierarchical_pipeline3(df, feature_names, standardize=True, use_pca=True)\n",
    "print('K-means 3 PCA:', score_k_3p)\n",
    "print('Hier. 3 PCA:', score_h_3p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Alt Original (step-by-step, StandardScaler):\")\n",
    "score_k_4, y_k_4 = run_kmeans_pipeline4(df, feature_names, standardize=True, use_pca=False)\n",
    "score_h_4, y_h_4 = run_hierarchical_pipeline4(df, feature_names, standardize=True, use_pca=False)\n",
    "print('K-means 4:', score_k_4)\n",
    "print('Hier. 4:', score_h_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Alt Original PCA(step-by-step, StandardScaler):\")\n",
    "score_k_4p, y_k_4p = run_kmeans_pipeline4(df, feature_names, standardize=True, use_pca=True)\n",
    "score_h_4p, y_h_4p = run_hierarchical_pipeline4(df, feature_names, standardize=True, use_pca=True)\n",
    "print('K-means 4 PCA:', score_k_4p)\n",
    "print('Hier. 4 PCA:', score_h_4p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pipeline - custom scaling:\")\n",
    "score_k_5, y_k_5 = run_kmeans_pipeline5(df, feature_names, standardize=True, use_pca=False)\n",
    "score_h_5, y_h_5 = run_hierarchical_pipeline5(df, feature_names, standardize=True, use_pca=False)\n",
    "print('K-means 5:', score_k_5)\n",
    "print('Hier. 5:', score_h_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pipeline PCA - custom scaling:\")\n",
    "score_k_5p, y_k_5p = run_kmeans_pipeline5(df, feature_names, standardize=True, use_pca=True)\n",
    "score_h_5p, y_h_5p = run_hierarchical_pipeline5(df, feature_names, standardize=True, use_pca=True)\n",
    "print('K-means PCA 5:', score_k_5p)\n",
    "print('Hier. PCA 5:', score_h_5p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of all scorings:\n",
    "--------------------\n",
    "* K-means 1: 0.3732994909365581\t\tpipeline\n",
    "* K-means 2: 0.5251916981567151\t\tstep-by-step  <--- WHAT IS GOING ON HERE?\n",
    "* K-means 3: 0.3732994909365581\t\talt pipeline\n",
    "* K-means 4: 0.3732994909365581\t\tstep-by-step StandardScaler\n",
    "* K-means 5: 0.3732994909365581\t\tpipeline custom scaler\n",
    "\n",
    "* K-means PCA 1: 0.3732994909365581\tpipeline\n",
    "* K-means PCA 2: 0.5272951661092291\tstep-by-step\t<--- WHAT IS GOING ON HERE?\n",
    "* K-means PCA 3: 0.3834680571101721\talt pipeline\n",
    "* K-means PCA 4: 0.3732994909365581\tstep-by-step StandardScaler\n",
    "* K-means PCA 5: 0.3834680571101721\tpipeline custom scaler\n",
    "\n",
    "* Hier. 1: 0.7100243618056425\t\tpipeline \n",
    "* Hier. 2: 0.5543189694833234\t\tstep-by-step\t <--- WHAT IS GOING ON HERE?\n",
    "* Hier. 3: 0.7100243618056425\t\talt pipeline\n",
    "* Hier. 4: 0.7100243618056425\t\tstep-by-step StandardScaler\n",
    "* Hier. 5: 0.7100243618056425\t\tpipeline custom scaler\n",
    "\n",
    "* Hier. PCA 1: 0.7100243618056425\t\tpipeline \n",
    "* Hier. PCA 2: 0.5543189694833234\t\tstep-by-step\t<--- WHAT IS GOING ON HERE?\n",
    "* Hier. PCA 3: 0.7100243618056425\t\talt pipeline\n",
    "* Hier. PCA 4: 0.7100243618056425\t\tstep-by-step StandardScaler\n",
    "* Hier. PCA 5: 0.7100243618056425\t\tpipeline custom scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's not the standardscaler or pipeline, there is someing in the step-by-step impl.\n",
    "\n",
    "(after close inspection, I found it. It's the score calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ORIGINAL ALT SCORE (step-by-step):\")\n",
    "score_k_6, y_k_6 = run_kmeans_pipeline6(df, feature_names, standardize=True, use_pca=False)\n",
    "score_h_6, y_h_6 = run_hierarchical_pipeline6(df, feature_names, standardize=True, use_pca=False)\n",
    "print('K-means 6:', score_k_6)\n",
    "print('Hier. 6:', score_h_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ORIGINAL ALT SCORE PCA (step-by-step):\")\n",
    "score_k_6p, y_k_6p = run_kmeans_pipeline6(df, feature_names, standardize=True, use_pca=True)\n",
    "score_h_6p, y_h_6p = run_hierarchical_pipeline6(df, feature_names, standardize=True, use_pca=True)\n",
    "print('K-means PCA 6:', score_k_6p)\n",
    "print('Hier. PCA 6:', score_h_6p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is indeed the same as all the other implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Issue solved! it was the scoring\n",
    "\n",
    "(the original step-by-step used the normalized data to calculate the silouette score, while all other variant are using the unnormalized data).\n",
    "\n",
    "Hence, running the pipeline without normalization will give a higher score (see next step), though that does not mean it's better. Needs visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ml_pipelines(df, feature_names, standardize=False, use_pca=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to make it the same as the 'step-by-step' outcome, I need to calc the score of the pipeline output with the normalized features (which are in the dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ml_pipelines(df, feature_names, standardize=True, use_pca=False)\n",
    "norm_features = imgutils.normalized_names(feature_names)\n",
    "x_base = df[norm_features]\n",
    "print('\\nRe-calculating scores...:')\n",
    "print('Score k-means (norm): ', silhouette_score(x_base, df['kmeans']))\n",
    "print('Score hier. (norm): ', silhouette_score(x_base, df['hierarchical']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is indeed (almost) identical to original step-by-step. Problem resolved!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize with and without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (8,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ml_pipelines(df, feature_names, standardize=True, use_pca=True)\n",
    "print(\"WITH NORMALIZATION:\")\n",
    "imgutils.show_large_heatmap(df, 'kmeans', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=s)\n",
    "imgutils.show_large_heatmap(df, 'hierarchical', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ml_pipelines(df, feature_names, standardize=False, use_pca=True)\n",
    "print(\"NO NORMALIZATION:\")\n",
    "imgutils.show_large_heatmap(df, 'kmeans', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=s)\n",
    "imgutils.show_large_heatmap(df, 'hierarchical', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks like hierarchical works better without normalization, k-means with normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 6. Conclusions & Next Steps\n",
    "\n",
    "* Scoring issue is resolved!\n",
    "* The difference is not coming from any software error\n",
    "* It depends on how the score is calculated; using the unnormalized or normalized data as basis (though normalized data is used for the unsupervised learning)  \n",
    "* For this data, hierarchical clustering works better without normalization. \n",
    "### Next Step: Back to the full pipeline development!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
