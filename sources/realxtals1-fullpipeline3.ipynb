{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pipeline (on Asbestos) - Oct 2018\n",
    "Created:  31 Oct 2018 <br>\n",
    "Last update: 1 Nov 2018\n",
    "\n",
    "\n",
    "### Goal: Run the full pipeline on the Asbestos set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this will remove warnings messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import imgutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Re-run this cell if you altered imgutils\n",
    "import importlib\n",
    "importlib.reload(imgutils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 2. Data Definitions & Feature Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Data:\n",
    "datafolder = '../data/Asbestos_Aug30/SA_TileSet_Subset2_1K'\n",
    "n_tiles_x = 2  # mostly for visualization\n",
    "n_tiles_y = 2\n",
    "\n",
    "\n",
    "# Features to use:\n",
    "#feature_funcs = [imgutils.img_mean, imgutils.img_std, imgutils.img_median, \n",
    "#                 imgutils.img_mode,\n",
    "#                 imgutils.img_kurtosis, imgutils.img_skewness]\n",
    "feature_funcs = [imgutils.img_std, imgutils.img_relstd, imgutils.img_mean, \n",
    "                 imgutils.img_skewness,  imgutils.img_kurtosis, imgutils.img_mode, imgutils.img_range]\n",
    "feature_names = imgutils.stat_names(feature_funcs)\n",
    "\n",
    "# Size of the grid, specified as number of slices per image in x and y direction:\n",
    "default_grid_x = 8\n",
    "default_grid_y = default_grid_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 3. Import Data & Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# image import:\n",
    "print(\"Scanning for images in '{}'...\".format(datafolder))\n",
    "df_imgfiles = imgutils.scanimgdir(datafolder, '.tif')\n",
    "imgfiles = list(df_imgfiles['filename'])\n",
    "print(\"# of images: {} \\n\".format(len(imgfiles)))\n",
    "\n",
    "# feature extraction:\n",
    "print(\"Feature extraction...\")\n",
    "print(\"- Slicing up images in {} x {} patches. \".format(default_grid_y, default_grid_x))\n",
    "print(\"- Extract statistics from each slice: {} \".format(', '.join(feature_names)))\n",
    "print(\"...working...\", end='\\r')\n",
    "df = imgutils.slicestats(imgfiles, default_grid_y, default_grid_x, feature_funcs)\n",
    "print(\"# slices extracted: \", len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 4. Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data hyper-parameters\n",
    "default_n_clusters = 3\n",
    "\n",
    "# algorithm hyper-parameters:\n",
    "kmeans_n_init = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_ml_pipeline2(X, ml_name, ml_algorithm, standardize=True, use_pca=True, n_pca=None):\n",
    "  \n",
    "    # Setup algorithmic pipeline, including standardization\n",
    "    pipeline = Pipeline([(ml_name, ml_algorithm)])\n",
    "    \n",
    "    # watch the order, pca should happen after scaling, but we insert at 0\n",
    "    if (use_pca): \n",
    "        pipeline.steps.insert(0,('pca', PCA(n_components=n_pca)))\n",
    "    if (standardize): \n",
    "        pipeline.steps.insert(0, ('scaling_{0}'.format(ml_name), StandardScaler()))\n",
    "    \n",
    "    # run the pipelines\n",
    "    y = pipeline.fit_predict(X) # calls predict on last step to get the labels\n",
    "\n",
    "    # report score:\n",
    "    score = silhouette_score(X, y)\n",
    "    \n",
    "    return score, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_ml_pipelines2(df_data, feature_cols, n_clusters, standardize=True, use_pca=True, n_pca=None):\n",
    "    global kmeans_n_init\n",
    "    \n",
    "    X = df_data.loc[:,feature_cols]\n",
    "    \n",
    "    # Setup ML clustering algorithms:    \n",
    "    kmeans = KMeans(algorithm='auto', n_clusters=n_clusters, n_init=kmeans_n_init, init='k-means++')\n",
    "    agglomerative =  AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='complete')  \n",
    "\n",
    "    # run the pipelines\n",
    "    print(\"Executing clustering pipelines...\")\n",
    "    score_kmeans, y_kmeans = run_ml_pipeline2(X, 'kmeans', kmeans, standardize = standardize, use_pca = use_pca, n_pca=n_pca)\n",
    "    score_hier, y_hier = run_ml_pipeline2(X, 'hierarchical', agglomerative, standardize = standardize, use_pca = use_pca, n_pca=n_pca)\n",
    "    print(\"Done\\n\")\n",
    "    \n",
    "    # collect data\n",
    "    df_data['kmeans']=y_kmeans\n",
    "    df_data['hierarchical']=y_hier\n",
    "\n",
    "    # report results:\n",
    "    print(\"\\nClustering Scores:\")\n",
    "    print(\"K-means: \", score_kmeans)\n",
    "    print(\"Hierarchical: \", score_hier)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_ml_pipelines2(df, feature_names, default_n_clusters, standardize=True, use_pca=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgutils.showimgset(imgfiles, 2,2, fig_size=(12, 8), relspacing=(0.05,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['dummy'] = 0\n",
    "imgutils.show_large_heatmap(df, 'dummy', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgutils.show_large_heatmap(df, 'kmeans', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgfile1 = imgfiles[2]\n",
    "#df_heats1 = df[df['filename']==imgfile1]['kmeans']\n",
    "#heats = np.reshape(df_heats1.values, (default_grid_y, default_grid_x))\n",
    "\n",
    "subimgs, heats = imgutils.getimgslices_fromdf(df, imgfile1, 'kmeans')\n",
    "heats = heats / np.max(heats)\n",
    "imgutils.showheatmap(subimgs, heats, cmapname='Set1', heatdepend_opacity = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_patches = 20\n",
    "df2 = imgutils.slicestats([imgfile1], n_patches, n_patches, feature_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_ml_pipelines2(df2, ['img_std', 'img_range'], 3, standardize=True, use_pca=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgutils.show_large_heatmap(df2, 'kmeans', [imgfile1], n_rows=1, n_cols=1, fig_size=(14,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgutils.showimgset(imgfiles, 2,2, fig_size=(12, 8), relspacing=(0.05,0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For nice graphs, run it once more with two clusters and two levels of granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def change_clusternums(df, columnname, oldnew_dict):\n",
    "    df[columnname].replace(oldnew_dict, inplace=True)\n",
    "    \n",
    "def swap_clusters(df, columnname, clust1, clust2):\n",
    "    oldnew_dict = { clust1: clust2, clust2: clust1}\n",
    "    df[columnname].replace(oldnew_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_patches = 4\n",
    "df_coarse = imgutils.slicestats([imgfile1], n_patches, n_patches, feature_funcs)\n",
    "run_ml_pipelines2(df_coarse, feature_names, 2, standardize=True, use_pca=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "swap_clusters(df_coarse, 'kmeans', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgutils.show_large_heatmap(df_coarse, 'kmeans', [imgfile1], n_rows=1, n_cols=1, fig_size=(10,10))\n",
    "imgutils.show_large_heatmap(df_coarse, 'kmeans', [imgfile1], n_rows=1, n_cols=1, fig_size=(10,10), heatdependent_opacity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Fine grained **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_patches = 20\n",
    "df_fine = imgutils.slicestats([imgfile1], n_patches, n_patches, feature_funcs)\n",
    "run_ml_pipelines2(df_fine, feature_names, 2, standardize=True, use_pca=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#swap_clusters(df_fine, 'kmeans', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgutils.show_large_heatmap(df_fine, 'kmeans', [imgfile1], n_rows=1, n_cols=1, fig_size=(10,10))\n",
    "imgutils.show_large_heatmap(df_fine, 'kmeans', [imgfile1], n_rows=1, n_cols=1, fig_size=(10,10), heatdependent_opacity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use other scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting the ml_pipeline to use silhouette scoring based on it's last transformation:\n",
    "(later renamed the other ones to run_xxx2 to preserve them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import calinski_harabaz_score\n",
    "\n",
    "def run_ml_pipeline(X, ml_name, ml_algorithm, standardize=True, use_pca=True, n_pca=None):\n",
    "  \n",
    "    # Setup 'manual' pipeline (not using sklearn pipeline as intermediates are needed)\n",
    "    feat_data = X\n",
    "    if (standardize): \n",
    "        standardizer = StandardScaler()\n",
    "        X_norm = standardizer.fit_transform(X)     \n",
    "        feat_data = X_norm\n",
    "    if (use_pca):  \n",
    "        pca = PCA(n_components=n_pca)\n",
    "        X_pca = pca.fit_transform(feat_data)\n",
    "        feat_data = X_pca\n",
    "    \n",
    "    # run the pipelines\n",
    "    y = ml_algorithm.fit_predict(feat_data) # calls predict oto get the labels\n",
    "\n",
    "    # report score:\n",
    "    #score = silhouette_score(feat_data, y)\n",
    "    score = calinski_harabaz_score(feat_data,y)\n",
    "    \n",
    "    return score, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_ml_pipelines(df_data, feature_cols, n_clusters, standardize=True, use_pca=True, n_pca=None):\n",
    "    global kmeans_n_init\n",
    "    \n",
    "    X = df_data.loc[:,feature_cols]\n",
    "    \n",
    "    # Setup ML clustering algorithms:    \n",
    "    kmeans = KMeans(algorithm='auto', n_clusters=n_clusters, n_init=kmeans_n_init, init='k-means++')\n",
    "    agglomerative =  AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='complete')  \n",
    "\n",
    "    # run the pipelines\n",
    "    print(\"Executing clustering pipelines...\")\n",
    "    score_kmeans, y_kmeans = run_ml_pipeline(X, 'kmeans', kmeans, standardize = standardize, use_pca = use_pca, n_pca=n_pca)\n",
    "    score_hier, y_hier = run_ml_pipeline(X, 'hierarchical', agglomerative, standardize = standardize, use_pca = use_pca, n_pca=n_pca)\n",
    "    print(\"Done\\n\")\n",
    "    \n",
    "    # collect data\n",
    "    df_data['kmeans']=y_kmeans\n",
    "    df_data['hierarchical']=y_hier\n",
    "\n",
    "    # report results:\n",
    "    print(\"\\nClustering Scores:\")\n",
    "    print(\"K-means: \", score_kmeans)\n",
    "    print(\"Hierarchical: \", score_hier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_ml_pipelines(df, feature_names, default_n_clusters, standardize=True, use_pca=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More consistent with previous results and imo it is indeed better to assess the algorithm on how good it could cluster after all pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgutils.showimgset(imgfiles, 2,2, fig_size=(12, 8), relspacing=(0.05,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_ml_pipelines(df, feature_names, default_n_clusters, standardize=True, use_pca=True)\n",
    "s = (12,10)\n",
    "imgutils.show_large_heatmap(df, 'kmeans', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=s)\n",
    "imgutils.show_large_heatmap(df, 'hierarchical', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Here Hierarchical outperforms kmeans **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run it again without PCA and/pr normalization compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_ml_pipelines(df, feature_names, default_n_clusters, standardize=True, use_pca=False)\n",
    "imgutils.show_large_heatmap(df, 'kmeans', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=s)\n",
    "imgutils.show_large_heatmap(df, 'hierarchical', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_ml_pipelines(df, feature_names, default_n_clusters, standardize=False, use_pca=False)\n",
    "imgutils.show_large_heatmap(df, 'kmeans', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=s)\n",
    "imgutils.show_large_heatmap(df, 'hierarchical', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On this dataset, not much difference between hierarchical and pca, with or without normalization \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combine import and pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def import_data(imagefolder):\n",
    "    df_imgfiles = imgutils.scanimgdir(imagefolder, '.tif')\n",
    "    return list(df_imgfiles['filename'])  \n",
    "\n",
    "def extract_features(imgfiles, feature_funcs, n_grid_rows, n_grid_cols):\n",
    "    df = imgutils.slicestats(imgfiles, n_grid_rows, n_grid_cols, feature_funcs)\n",
    "    feature_names = imgutils.stat_names(feature_funcs)\n",
    "    return df, feature_names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_kmeans_pipeline(df_data, feature_cols, n_clusters, standardize=True, use_pca=True, n_pca= None):\n",
    "    global kmeans_n_init\n",
    "   \n",
    "    ml_name=\"kmeans\"\n",
    "    ml_algorithm = KMeans(algorithm='auto', n_clusters=n_clusters, n_init=kmeans_n_init, init='k-means++')\n",
    "\n",
    "    X = df_data.loc[:,feature_cols]    \n",
    "    score, y = run_ml_pipeline(X, ml_name, ml_algorithm, standardize = standardize, use_pca = use_pca, n_pca=n_pca)\n",
    "    df_data[ml_name]= y\n",
    "\n",
    "    return score\n",
    "\n",
    "def run_hierarchical_pipeline(df_data, feature_cols, n_clusters, standardize=True, use_pca=True, n_pca=None):\n",
    "\n",
    "    ml_name=\"hierarchical\"\n",
    "    ml_algorithm =  AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='complete')  \n",
    "\n",
    "    X = df_data.loc[:,feature_cols]    \n",
    "    score, y = run_ml_pipeline(X, ml_name, ml_algorithm, standardize = standardize, use_pca = use_pca, n_pca=n_pca)\n",
    "    df_data[ml_name]= y\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_fullpipeline(imagefolder, n_image_rows, n_image_cols, \n",
    "                     n_grid_rows, n_grid_cols, feature_funcs, n_clusters, fig_size=(8,6), return_df = False):\n",
    "    \"\"\"\n",
    "    Run the full pipeline from import to visualization.   \n",
    "    \"\"\" \n",
    "    print(\"Working...\\r\")\n",
    "    imgfiles = import_data(imagefolder)\n",
    "    df, feature_names = extract_features(imgfiles, feature_funcs, n_grid_rows, n_grid_cols)\n",
    "    print(feature_names)\n",
    "    score_kmeans = run_kmeans_pipeline(df, feature_names, n_clusters, standardize=True, use_pca=True )\n",
    "    score_hier = run_hierarchical_pipeline(df, feature_names, n_clusters, standardize=False, use_pca=False)\n",
    "\n",
    "    print('Results:')\n",
    "    print('Score k-means:', score_kmeans)\n",
    "    print('Score hierarchical:', score_hier)\n",
    "    \n",
    "    print('Visualizing...')\n",
    "    imgutils.show_large_heatmap(df, 'kmeans', imgfiles, n_rows=n_image_rows, n_cols=n_image_cols, fig_size=fig_size)\n",
    "    imgutils.show_large_heatmap(df, 'hierarchical', imgfiles, n_rows=n_image_rows, n_cols=n_image_cols, fig_size=fig_size)\n",
    "    \n",
    "    if return_df: return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_fullpipeline_kmeans(imagefolder, n_image_rows, n_image_cols, \n",
    "                     n_grid_rows, n_grid_cols, feature_funcs, n_clusters, fig_size=(8,6), return_df = False):\n",
    "    \"\"\"\n",
    "    Run the full pipeline from import to visualization.   \n",
    "    \"\"\" \n",
    "    print(\"Working...\\r\")\n",
    "    imgfiles = import_data(imagefolder)\n",
    "    df, feature_names = extract_features(imgfiles, feature_funcs, n_grid_rows, n_grid_cols)\n",
    "    print(feature_names)\n",
    "    score_kmeans = run_kmeans_pipeline(df, feature_names, n_clusters, standardize=True, use_pca=True )\n",
    "\n",
    "    print('Results:')\n",
    "    print('Score k-means:', score_kmeans)\n",
    "    \n",
    "    print('Visualizing...')\n",
    "    imgutils.show_large_heatmap(df, 'kmeans', imgfiles, n_rows=n_image_rows, n_cols=n_image_cols, fig_size=fig_size)\n",
    "    \n",
    "    if return_df: return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_fullpipeline_hierarchical(imagefolder, n_image_rows, n_image_cols, \n",
    "                     n_grid_rows, n_grid_cols, feature_funcs, n_clusters, fig_size=(8,6), return_df = False):\n",
    "    \"\"\"\n",
    "    Run the full pipeline from import to visualization.   \n",
    "    \"\"\" \n",
    "    print(\"Working...\\r\")\n",
    "    imgfiles = import_data(imagefolder)\n",
    "    df, feature_names = extract_features(imgfiles, feature_funcs, n_grid_rows, n_grid_cols)\n",
    "    print(feature_names)\n",
    "    score_hier = run_hierarchical_pipeline(df, feature_names, n_clusters, standardize=False, use_pca=False)\n",
    "\n",
    "    print('Results:')\n",
    "    print('Score hierarchical:', score_hier)\n",
    "    \n",
    "    print('Visualizing...')\n",
    "    imgutils.show_large_heatmap(df, 'hierarchical', imgfiles, n_rows=n_image_rows, n_cols=n_image_cols, fig_size=fig_size)\n",
    "    \n",
    "    if return_df: return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Try it out with different combinations of slices on a harder variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datafolder = '../data/Asbestos_Aug30/SA_TileSet_Subset1_1K'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4x4 - 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_fullpipeline(datafolder, n_tiles_y, n_tiles_x, 4, 4, feature_funcs, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8x8, 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_fullpipeline(datafolder, n_tiles_y, n_tiles_x, 8, 8, feature_funcs, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20x20, 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_fullpipeline(datafolder, n_tiles_y, n_tiles_x, 20, 20, feature_funcs, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 8. Try it out with different number of clusters\n",
    "\n",
    "### 2 clusters (4x4 , 10x10, 20x20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_fullpipeline_kmeans(datafolder, n_tiles_y, n_tiles_x, 4, 4, feature_funcs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_fullpipeline_kmeans(datafolder, n_tiles_y, n_tiles_x, 10, 10, feature_funcs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_fullpipeline_kmeans(datafolder, n_tiles_y, n_tiles_x, 20, 20, feature_funcs, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look again at hierarchical with scaling and pca on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(feature_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no difference, all not good.  Let's try if we drop the mean and mode (see if ignores the black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try_funcs =  [imgutils.img_std, imgutils.img_relstd, imgutils.img_skewness,imgutils.img_kurtosis]\n",
    "run_fullpipeline_kmeans(datafolder, n_tiles_y, n_tiles_x, 8, 8, try_funcs , 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 clusters (4x4, 10x10, 20x20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_fullpipeline_kmeans(datafolder, n_tiles_y, n_tiles_x, 4, 4, feature_funcs, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_fullpipeline_kmeans(datafolder, n_tiles_y, n_tiles_x, 10, 10, feature_funcs, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_fullpipeline_kmeans(datafolder, n_tiles_y, n_tiles_x, 20, 20, feature_funcs, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** with smaller grid and 4 clusters, it starts to make sense **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_fullpipeline_hierarchical(datafolder, n_tiles_y, n_tiles_x, 10, 10, feature_funcs, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** AGAIN, THE BLACK TILES NEGATIVELY IMPACT RESULTS **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try two-step pipeline\n",
    "## step 1: filter out black tiles\n",
    "## step 2: cluster remaining tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametrize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_clusters_step1 = 3\n",
    "n_clusters_step2_kmeans = 2\n",
    "n_clusters_step2_hierarchical = 2\n",
    "\n",
    "n_patches_x = 10\n",
    "n_patches_y = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def change_clusternums(df, columnname, oldnew_dict):\n",
    "    df[columnname].replace(oldnew_dict, inplace=True)\n",
    "    \n",
    "def swap_clusters(df, columnname, clust1, clust2):\n",
    "    oldnew_dict = { clust1: clust2, clust2: clust1}\n",
    "    df[columnname].replace(oldnew_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# reset\n",
    "df = df.drop(columns=['kmeans'])\n",
    "df2 = None\n",
    "df3 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgfiles = import_data(datafolder)\n",
    "df, feature_names = extract_features(imgfiles, feature_funcs, n_patches_y, n_patches_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgutils.showimgset(imgfiles, 2,2, fig_size=(12, 8), relspacing=(0.05,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['dummy']=0\n",
    "imgutils.show_large_heatmap(df, 'dummy', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=(12,12))\n",
    "imgutils.show_large_heatmap(df, 'dummy', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=(12,12), no_borders=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: filter-out black tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = run_kmeans_pipeline(df, feature_names, n_clusters_step1, standardize=True, use_pca=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swap_clusters(df,'kmeans', 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgutils.show_large_heatmap(df, 'kmeans', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgutils.show_large_heatmap(df, 'kmeans', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=(12,12), heatdependent_opacity=True, no_borders=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['kmeans'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cat_select = 1  \n",
    "# we know for this it's the biggest set\n",
    "i_max_count = df['kmeans'].value_counts()\n",
    "cat_select = i_max_count.index[0]\n",
    "print(cat_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2 = df[df['kmeans']==cat_select]\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score_kmeans = run_kmeans_pipeline(df2, feature_names, n_clusters_step2_kmeans, standardize=True, use_pca=True )\n",
    "score_hierarch = run_hierarchical_pipeline(df2, feature_names, n_clusters_step2_hierarchical, standardize=False, use_pca=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2['kmeans'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2['hierarchical'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2=df2.rename(columns = {'kmeans':'kmeans2', 'hierarchical':'hierarchical2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3 = df.merge(df2, 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3['kmeans2'].fillna(value=-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3['hierarchical2'].fillna(value=-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3['heats']=df3['kmeans2']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3['heats'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make the whole 2 clusters only\n",
    "df3['heats'].replace({1:0}, inplace=True)\n",
    "df3['heats'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3['heats2']=df3['hierarchical2']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3['heats2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make the whole 2 clusters only\n",
    "df3['heats2'].replace({1:0}, inplace=True)\n",
    "df3['heats2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgutils.show_large_heatmap(df3, 'heats', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=(16,12))\n",
    "imgutils.show_large_heatmap(df3, 'heats', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=(16,12), heatdependent_opacity=True, no_borders=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgutils.show_large_heatmap(df3, 'heats2', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=(16,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Alternative: run one with 4 clusters and small patch-size **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_direct4 = run_fullpipeline_kmeans(datafolder, n_tiles_y, n_tiles_x, 12, 12, feature_funcs, 4, return_df = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swap_clusters(df_direct4, 'kmeans', 1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgutils.show_large_heatmap(df_direct4, 'kmeans', imgfiles, n_rows=n_tiles_y, n_cols=n_tiles_x, fig_size=(12,12), heatdependent_opacity=True, no_borders=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yet another set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datafolder_lm = '../data/Asbestos_Aug30/LM_TileSet_Subset_1K'\n",
    "imgfiles_lm = import_data(datafolder_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_fullpipeline_kmeans(datafolder_lm, n_tiles_y, n_tiles_x, 10, 10, feature_funcs, 3, fig_size=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_fullpipeline_kmeans(datafolder_lm, n_tiles_y, n_tiles_x, 10, 10, feature_funcs, 4,fig_size=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_fullpipeline_kmeans(datafolder_lm, n_tiles_y, n_tiles_x, 20, 20, feature_funcs, 4, fig_size=(12,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 step approach on this set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Parametrize **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_step1 = 3\n",
    "n_clusters_step2_kmeans = 2\n",
    "n_clusters_step2_hierarchical = 2\n",
    "\n",
    "n_patches_x = 20\n",
    "n_patches_y = 20\n",
    "\n",
    "n_tiles_x3 = 2\n",
    "n_tiles_y3 = 2\n",
    "\n",
    "datafolder3= '../data/Asbestos_Aug30/LM_TileSet_Subset_1K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset\n",
    "df = df.drop(columns=['kmeans'])\n",
    "df2 = None\n",
    "df3 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1. Filter black tiles **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgfiles3 = import_data(datafolder3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df, feature_names = extract_features(imgfiles3, feature_funcs, n_patches_y, n_patches_x)\n",
    "print(len(imgfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['dummy']=0\n",
    "imgutils.show_large_heatmap(df, 'dummy', imgfiles3, n_rows=n_tiles_y3, n_cols=n_tiles_x3, fig_size=(12,12))\n",
    "imgutils.show_large_heatmap(df, 'dummy', imgfiles3, n_rows=n_tiles_y3, n_cols=n_tiles_x3, fig_size=(12,12), no_borders=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = run_kmeans_pipeline(df, feature_names, n_clusters_step1, standardize=True, use_pca=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swap_clusters(df,'kmeans', 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgutils.show_large_heatmap(df, 'kmeans', imgfiles, n_rows=n_tiles_y3, n_cols=n_tiles_x3, fig_size=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['kmeans'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cat_select = 1  \n",
    "# we know for this it's the biggest set\n",
    "i_max_count = df['kmeans'].value_counts()\n",
    "cat_select = i_max_count.index[0]\n",
    "print(cat_select)\n",
    "df2 = df[df['kmeans']==cat_select]\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score_kmeans = run_kmeans_pipeline(df2, feature_names, n_clusters_step2_kmeans, standardize=True, use_pca=True )\n",
    "score_hierarch = run_hierarchical_pipeline(df2, feature_names, n_clusters_step2_hierarchical, standardize=False, use_pca=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2=df2.rename(columns = {'kmeans':'kmeans2', 'hierarchical':'hierarchical2'})\n",
    "df3 = df.merge(df2, 'left')\n",
    "df3['kmeans2'].fillna(value=-1, inplace=True)\n",
    "df3['hierarchical2'].fillna(value=-1, inplace=True)\n",
    "df3['heats']=df3['kmeans2']+1\n",
    "df3['heats2']=df3['hierarchical2']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['heats'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the whole 2 clusters only\n",
    "df3['heats'].replace({1:0}, inplace=True)\n",
    "df3['heats'].value_counts()\n",
    "\n",
    "# make the whole 2 clusters only\n",
    "df3['heats2'].replace({1:0}, inplace=True)\n",
    "df3['heats2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgutils.show_large_heatmap(df3, 'heats', imgfiles3, n_rows=n_tiles_y3, n_cols=n_tiles_x3, fig_size=(16,12))\n",
    "imgutils.show_large_heatmap(df3, 'heats2', imgfiles3, n_rows=n_tiles_y3, n_cols=n_tiles_x3, fig_size=(16,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### after filtering out the black ones, hierarchical clustering worked better than kmeans \n",
    "\n",
    "** This set needs smaller patches **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
